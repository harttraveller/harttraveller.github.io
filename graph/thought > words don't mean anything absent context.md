#future/med 

# Edge
- [[list > thoughts on linguistics]]

# Text
- consider "unlikely"
	- there is no absolute definition of unlikely, it is a subjective determination made given some context, eg
		- 'unlikely' in the context of falsifying a novel theory of quantum gravity, ~$6 \sigma$ (?)
		- 'unlikely' in the context of the Canucks winning the Stanley cup sometime in the next decade ~$2 \sigma$ (?)
- on one hand this is mildly frustrating - yet another instance of the imprecision of language
	- the issues with this lack of precision abound
		- allows for spin, misinterpretation,
- on the other, is actually probably extremely useful, and byproduct of CNS and cortex functioning essentially as a data compression mechanism - being able to infer meaning from context instead of specifying every detail in every situation is almost certainty far more useful than not
- conclusion(?) -> language is not "meaning", it leads a path through contexts in the mind, and that path is what is meaningful
	- potential implications:
		- just representing language accurately (eg: with dependency tree), or using LLMs, is not enough to achieve "true AGI"
			- reasoning being -> there is no underlying model of reality, only inference over the symbols we've superimposed on reality
				- this reasoning may be false
		- we need to also be able to represent mind, and context, and resolve the meaning of particular path given the contexts

