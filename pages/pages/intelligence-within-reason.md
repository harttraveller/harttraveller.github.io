---
title: Intelligence, within reason.
search:
  exclude: true
---

- we do not yet have "reasoning" artificial intelligence
    - we have stochastic chinese rooms - link other post
- so if, as the system seems to be demanding, we want to create intelligence "within reason" - ie: intelligence that is not simply an act of detonating a thermonuclear warhead in the heart of future society, then we need to adopt our expectations and approach for the impl3ementation of the automated simulacra of intelligence that we have available today
- namely, we don't have intelligence with good internal representations, the ability to build new spaces for netirely new representations, and make predictions about those representations, while organizing knowledge, and for lack of a better term, invoking the creative "spark" humans have
    - need to revise this sentence.
- I don't want to be an AI doomer (in the X sense. I am probably one in the eyes of some biological humanists)

solution: recognize limitations, instead of trying to force transformer models to be exhibit a more convincing simulacra of intelligence, recognize that *they aren't intelligent* (in a deeper sense), and do the following:

1. return to fundamental research
2. more importantly: if, as it seems folks with money and power are committed to trying to replace humans with this pseudo-intelligence - if they are committed to continuing down this path, then, instead of trying to create more effective simulacra, we should try to create more effective restrictions on the statistically-informed-yet-pseudo-random walk that that LLMs do through the space of tokens when they are generating stuff.

<!-- provide examples with SysML, volume restrictions -->

