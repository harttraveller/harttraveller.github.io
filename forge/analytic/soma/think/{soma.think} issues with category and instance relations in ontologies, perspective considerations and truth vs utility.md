#active 

Suppose we consider the entity [computer language > python] (as differentiated from [reptilian genus > python]).

The following is a snippet of python code. We'll refer to it as $S$.
```python
def multiply(x: int | float, y: int | float) -> int | float:
	"This function multiplies two numbers together."
	return x * y
```
Is the following statement true?

- $S$ -> `is instance of` -> `computer language > python`

I don't think we can say yes, as there is also english in $S$. Instead, a more accurate statement would be the statement with an `AND` operation between the following statements.

- $S$ -> `is instance of` -> `computer language > python`
- $S$ -> `is instance of` -> `human language > english`

But this is not entirely correct either, as $S$ as a discrete entity is not both at the same time, it is an instance of digital text information, which contains both english and python.

Furthermore, wouldn't what we *call* $S$ change depending on the perspective we look at it from?

For instance, if we[ctx > you and me, humans, reading this page] look at it, it is python. But if we look at it from a different perspective - say in the developer tools window - it is actually HTML. Specifically it is an HTML code block.

So then, is python the syntax? Or the medium? (executed code vs. rendered code for viewing)

Consider C++ instead. In this case, the C++ is no longer even the C++ syntax. The C++ code will be compiled before execution. Consider the perspective of a daemon watching the machine code run through the microprocessor architecture - aware of all of the transistor gates switching back and forth - without knowledge of what the original code even looks like.

In this case, we would probably say with some certainty that the C++ is no longer C++, but is now machine code in the process of execution on a chip.

What if, however, we took that same daemon and asked it to look at the bit string representing the python code at the top of the page?

I don't think the daemon would say it is python, I think it would say it is a string of bits. 

---

Perhaps we say: 

Well you see, if we pull you up a few abstraction levels to a place where you can see the string of bits rendered as a formal computer language, you would see that it is rendered in the `computer language > python`.

And it would respond:

OK, fine, so you've showed me that if I add a myriad new and different computational processes, such as the internet, javascript rendering, a screen, the screen rendering architecture, and so on, we finally get to the thing called `computer language > python` which the reader of this page sees and perceives it to be. But that isn't really what it is, it's a string of bits! And if you add on all this other stuff, then sure, there's a way you can look at it where it is the supposed python, but that is all an illusion you maintain.

At which point another daemon would show up and say:

Whoa, hang on a second. It isn't a string of bits, its a particular configuration of atoms and flows of electrons. And in fact, every instance this configuration of atoms and electrons you higher level daemons and humans see is an illusion manifested by your pattern recognition capabilities, which are also an illusion by the way. The only thing that is real is stuff down here with me, where they are particles bumping into particles in an endless and impossibly complex chain of causality.

---

The point here isn't really whether any of the daemons or humans are right or wrong in their assertions, its really that:

1. We can't know which of them are right or wrong, or the criteria or qualifications of their "rightness" or "wrongness".
2. Quite possibly they are all right, and wrong, at the same time. Because whether they are right or wrong depends not on whether what they describe is true, but only whether it is true given their subjective perspective.

Suppose we consider (2) to be true. What are the implications of this? First, I think we could say that an ontology that captures a complete perspective of reality is very hard, or perhaps impossible, purely on the basis that entities and relations which are represented such that the connections between them evaluate to being a "true representation" from one perspective, would evaluate to being a "false representation" from another.

We could try to resolve this by accounting for the above proposition, but representing reality could become extraordinarily complex quite fast.

If the above were true, or "true in a functional sense" at least...

> [!tangent] True in a functional sense
> By this I mean, perhaps not true for God, or some other omniscient entity, but true for us as humans in the present and immediate (~1000ish years) future.

...that would mean that when we create ontologies or in general systems for representing reality, we shouldn't be asking ourselves "is this a true representation of reality?", but we should be asking ourselves: "is this a useful representation of reality?".



